{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local Binary Pattern for Image Texture Classfication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "import glob2 as glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from skimage.transform import rotate\n",
    "from skimage.feature import local_binary_pattern\n",
    "from skimage import data\n",
    "from skimage.color import label2rgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = 'dataset\\\\Splited' # INSERT THE PATH TO THE DATASET\n",
    "\n",
    "# Define the paths to the train and test folders\n",
    "train_folder = os.path.join(dataset_folder, 'train')\n",
    "test_folder = os.path.join(dataset_folder, 'valid')\n",
    "\n",
    "# Retrieve the list of file names in the train folder\n",
    "train_classes_path = glob.glob(os.path.join(train_folder, \"*\"))\n",
    "\n",
    "# Retrieve the list of file names in the test folder\n",
    "validation_classes_path = glob.glob(os.path.join(test_folder, \"*\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chi-square distance\n",
    "def chi_square_distance(hist_P, hist_Q):\n",
    "    # Ensure histograms are not zero\n",
    "    hist_P[hist_P == 0] = 1e-10\n",
    "    hist_Q[hist_Q == 0] = 1e-10\n",
    "    \n",
    "    # Calculate the Chi-square distance\n",
    "    distance = np.sum((hist_P - hist_Q)**2 / (hist_P + hist_Q))\n",
    "    \n",
    "    return distance\n",
    "\n",
    "def chi2_distance(A, B):\n",
    " \n",
    "    # compute the chi-squared distance using above formula\n",
    "    chi = 0.5 * np.sum([((a - b) ** 2) / (a + b) \n",
    "                      for (a, b) in zip(A, B)])\n",
    "\n",
    "    return chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate LBP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_lbp(image): # custom implementation based on the adjacent negighbours\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Initialize the LBP image\n",
    "    lbp_image = np.zeros_like(gray)\n",
    "    pad_width = 1\n",
    "    gray = np.pad(gray, pad_width, mode='constant', constant_values=0)\n",
    "    \n",
    "    # Define 8 neighbors for each pixel\n",
    "    neighbors = [(-1, -1), (-1, 0), (-1, 1), (0, 1), (1, 1), (1, 0), (1, -1), (0, -1)]\n",
    "    \n",
    "    # Iterate over each pixel in the image\n",
    "    for i in range(1, gray.shape[0] - 1):\n",
    "        for j in range(1, gray.shape[1] - 1):\n",
    "            # Get the binary pattern\n",
    "            binary_pattern = ''\n",
    "            center_value = gray[i, j]\n",
    "            for dy, dx in neighbors:\n",
    "                neighbor_value = gray[i + dy, j + dx]\n",
    "                binary_pattern += '1' if neighbor_value >= center_value else '0'\n",
    "            \n",
    "            # Convert binary pattern to decimal\n",
    "            lbp_value = int(binary_pattern, 2)\n",
    "            # print(lbp_value)\n",
    "            \n",
    "            # Assign LBP value to corresponding pixel in LBP image\n",
    "            lbp_image[i-1, j-1] = lbp_value\n",
    "    \n",
    "    return lbp_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funcions to compare an image with an available class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_minimum_distance(image_hist, train_class_path, representations):\n",
    "    distances = []\n",
    "    train_files_path = glob.glob(os.path.join(train_class_path, \"*\"))\n",
    "    for train_image_path in train_files_path:\n",
    "\n",
    "        train_image_hist = representations[train_image_path]\n",
    "\n",
    "        distance = chi_square_distance(image_hist, train_image_hist)\n",
    "        distances.append(distance)\n",
    "\n",
    "    distances = np.array(distances)\n",
    "    index_of_min = np.argmin(distances)\n",
    "    file_min = train_files_path[index_of_min]\n",
    "    return distances.min(), file_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(image_path, train_classes_path, representations, representations_val):\n",
    "\n",
    "    image_hist = representations_val[image_path]\n",
    "\n",
    "    minimum_distances = []\n",
    "    file_mins = []\n",
    "\n",
    "    for train_class_path in train_classes_path:\n",
    "        min_distance_from_class, file_min = find_minimum_distance(image_hist, train_class_path, representations)\n",
    "        minimum_distances.append(min_distance_from_class)\n",
    "        file_mins.append(file_min)\n",
    "\n",
    "    minimum_distances = np.array(minimum_distances)\n",
    "    # print(minimum_distances)\n",
    "    \n",
    "    file_mins = np.array(file_mins) # the files that are most similar among the class members in the training set\n",
    "    # print(file_mins)\n",
    "    \n",
    "    class_index = np.argmin(minimum_distances)\n",
    "\n",
    "    return file_mins[class_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the LPB histogram representation of the training samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_lpb_representations(train_classes_path1):\n",
    "    representations = {}\n",
    "\n",
    "    for train_class_path in train_classes_path1:\n",
    "        train_files_path = glob.glob(os.path.join(train_class_path, \"*\"))\n",
    "        for train_image_path in train_files_path: \n",
    "            # read image\n",
    "            train_image = cv2.imread(train_image_path)\n",
    "            # compute the LBP for the two images\n",
    "            train_image_lbp = calculate_lbp(image2).ravel()\n",
    "\n",
    "            representations[train_image_path] = train_image_lbp\n",
    "\n",
    "    return representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = generate_lpb_representations(train_classes_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "representations_val = generate_lpb_representations(validation_classes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the comparison for all validation samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lbp = []\n",
    "for sample in representations_val:\n",
    "    prediction = classify_image(sample, train_classes_path, representations, representations_val)\n",
    "    predictions_lbp.append(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_lbp = [p.split(\"\\\\\")[-2] for p in predictions_lbp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_classes = [a.split(\"\\\\\")[-2] for a in representations_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      precision    recall  f1-score   support\n",
      "\n",
      "  KTH_aluminium_foil       0.05      1.00      0.09       216\n",
      "     KTH_brown_bread        nan      0.00       nan        41\n",
      "        KTH_corduroy        nan      0.00       nan       256\n",
      "            KTH_cork        nan      0.00       nan       216\n",
      "          KTH_cotton        nan      0.00       nan       257\n",
      "         KTH_cracker        nan      0.00       nan        34\n",
      "           KTH_linen        nan      0.00       nan       257\n",
      "     KTH_orange_peel        nan      0.00       nan        25\n",
      "          KTH_sponge        nan      0.00       nan        41\n",
      "       KTH_styrofoam        nan      0.00       nan        41\n",
      "            KTH_wool        nan      0.00       nan       216\n",
      "    Kyberge_blanket1        nan      0.00       nan        80\n",
      "    Kyberge_blanket2        nan      0.00       nan        80\n",
      "     Kyberge_canvas1        nan      0.00       nan        80\n",
      "    Kyberge_ceiling1        nan      0.00       nan        80\n",
      "    Kyberge_ceiling2        nan      0.00       nan        80\n",
      "    Kyberge_cushion1        nan      0.00       nan        80\n",
      "      Kyberge_floor1        nan      0.00       nan        80\n",
      "      Kyberge_floor2        nan      0.00       nan        80\n",
      "      Kyberge_grass1        nan      0.00       nan        80\n",
      "    Kyberge_lentils1        nan      0.00       nan        80\n",
      "   Kyberge_linseeds1        nan      0.00       nan        80\n",
      "    Kyberge_oatmeal1        nan      0.00       nan        80\n",
      " Kyberge_pearlsugar1        nan      0.00       nan        80\n",
      "       Kyberge_rice1        nan      0.00       nan        80\n",
      "       Kyberge_rice2        nan      0.00       nan        80\n",
      "        Kyberge_rug1        nan      0.00       nan        80\n",
      "       Kyberge_sand1        nan      0.00       nan        80\n",
      "      Kyberge_scarf1        nan      0.00       nan        80\n",
      "      Kyberge_scarf2        nan      0.00       nan        80\n",
      "     Kyberge_screen1        nan      0.00       nan        80\n",
      "       Kyberge_seat1        nan      0.00       nan        80\n",
      "       Kyberge_seat2        nan      0.00       nan        80\n",
      "Kyberge_sesameseeds1        nan      0.00       nan        80\n",
      "      Kyberge_stone1        nan      0.00       nan        80\n",
      "      Kyberge_stone2        nan      0.00       nan        80\n",
      "      Kyberge_stone3        nan      0.00       nan        80\n",
      "  Kyberge_stoneslab1        nan      0.00       nan        80\n",
      "       Kyberge_wall1        nan      0.00       nan        80\n",
      "        UIUC01_bark1        nan      0.00       nan        20\n",
      "        UIUC02_bark2        nan      0.00       nan        20\n",
      "        UIUC03_bark3        nan      0.00       nan        20\n",
      "        UIUC04_wood1        nan      0.00       nan        20\n",
      "        UIUC05_wood2        nan      0.00       nan        20\n",
      "        UIUC06_wood3        nan      0.00       nan        20\n",
      "        UIUC07_water        nan      0.00       nan        20\n",
      "      UIUC08_granite        nan      0.00       nan        20\n",
      "       UIUC09_marble        nan      0.00       nan        20\n",
      "       UIUC10_floor1        nan      0.00       nan        20\n",
      "       UIUC11_floor2        nan      0.00       nan        20\n",
      "      UIUC12_pebbles        nan      0.00       nan        20\n",
      "         UIUC13_wall        nan      0.00       nan        20\n",
      "       UIUC14_brick1        nan      0.00       nan        20\n",
      "       UIUC15_brick2        nan      0.00       nan        20\n",
      "       UIUC16_glass1        nan      0.00       nan        20\n",
      "       UIUC17_glass2        nan      0.00       nan        20\n",
      "      UIUC18_carpet1        nan      0.00       nan        20\n",
      "      UIUC19_carpet2        nan      0.00       nan        20\n",
      "   UIUC20_upholstery        nan      0.00       nan        20\n",
      "    UIUC21_wallpaper        nan      0.00       nan        20\n",
      "          UIUC22_fur        nan      0.00       nan        20\n",
      "         UIUC23_knit        nan      0.00       nan        20\n",
      "     UIUC24_corduroy        nan      0.00       nan        20\n",
      "        UIUC25_plaid        nan      0.00       nan        20\n",
      "\n",
      "            accuracy                           0.05      4340\n",
      "           macro avg       0.05      0.02      0.09      4340\n",
      "        weighted avg       0.05      0.05      0.09      4340\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual_classes,predictions_lbp,zero_division=np.nan))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
